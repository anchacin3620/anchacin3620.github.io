<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>El Método de Monte Carlo - Informe Académico</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism.min.css">
    <!-- MathJax para renderizar ecuaciones -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        :root {
            --primary-color: #6A1B9A; /* Morado intenso */
            --secondary-color: #FF6F00; /* Naranja vibrante */
            --accent-color: #00C853; /* Verde brillante */
            --light-color: #F3E5F5;
            --dark-color: #4A148C;
            --text-color: #212121;
            --gray-color: #757575;
            --bg-color: #F9F9F9;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
        }
        
        .container {
            width: 90%;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
            padding: 2rem 0;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            position: relative;
            z-index: 10;
        }
        
        header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        
        .author-info {
            margin-top: 1rem;
            font-size: 1rem;
            font-style: italic;
        }
        
        /* Menú desplegable */
        .menu-toggle {
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 1001;
            background-color: var(--dark-color);
            color: white;
            border: none;
            border-radius: 5px;
            padding: 10px;
            cursor: pointer;
            font-size: 1.2rem;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: all 0.3s ease;
        }
        
        .menu-toggle:hover {
            background-color: var(--secondary-color);
        }
        
        .side-menu {
            position: fixed;
            top: 0;
            left: -300px;
            width: 300px;
            height: 100vh;
            background-color: var(--dark-color);
            padding-top: 70px;
            transition: left 0.3s ease;
            z-index: 1000;
            box-shadow: 2px 0 5px rgba(0, 0, 0, 0.1);
            overflow-y: auto;
        }
        
        .side-menu.active {
            left: 0;
        }
        
        .side-menu ul {
            list-style: none;
            padding: 0;
        }
        
        .side-menu li {
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .side-menu a {
            display: block;
            color: white;
            text-decoration: none;
            padding: 15px 20px;
            transition: background-color 0.3s ease;
        }
        
        .side-menu a:hover {
            background-color: var(--secondary-color);
        }
        
        .overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 999;
            opacity: 0;
            visibility: hidden;
            transition: all 0.3s ease;
        }
        
        .overlay.active {
            opacity: 1;
            visibility: visible;
        }
        
        .section {
            background-color: white;
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);
        }
        
        .section h2 {
            color: var(--primary-color);
            margin-bottom: 20px;
            font-size: 1.8rem;
            border-bottom: 2px solid var(--accent-color);
            padding-bottom: 10px;
        }
        
        .section h3 {
            color: var(--secondary-color);
            margin: 15px 0 10px;
            font-size: 1.3rem;
        }
        
        .section h4 {
            color: var(--dark-color);
            margin: 10px 0;
            font-size: 1.1rem;
        }
        
        .section p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        .section ul, .section ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        
        .section li {
            margin-bottom: 8px;
        }
        
        .table-container {
            overflow-x: auto;
            margin: 20px 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        
        table th, table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        
        table th {
            background-color: var(--light-color);
            color: var(--dark-color);
        }
        
        table tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        
        .highlight {
            background-color: var(--light-color);
            padding: 15px;
            border-left: 4px solid var(--accent-color);
            margin: 20px 0;
            border-radius: 5px;
        }
        
        .formula {
            background-color: var(--light-color);
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            text-align: center;
            font-family: 'Times New Roman', Times, serif;
            font-size: 1.1rem;
        }
        
        .interactive-demo {
            background-color: var(--light-color);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            text-align: center;
        }
        
        .demo-controls {
            margin: 15px 0;
            display: flex;
            justify-content: center;
            gap: 10px;
            flex-wrap: wrap;
        }
        
        button {
            background-color: var(--secondary-color);
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s ease;
        }
        
        button:hover {
            background-color: var(--dark-color);
        }
        
        .canvas-container {
            margin: 20px 0;
            display: flex;
            justify-content: center;
        }
        
        canvas {
            border: 1px solid var(--gray-color);
            border-radius: 5px;
            background-color: white;
        }
        
        .code-block {
            background-color: #f5f5f5;
            border-radius: 5px;
            margin: 15px 0;
            overflow-x: auto;
        }
        
        pre {
            margin: 0;
        }
        
        .tabs {
            display: flex;
            margin-bottom: 0;
            border-bottom: 2px solid var(--light-color);
        }
        
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            background-color: var(--light-color);
            border-radius: 5px 5px 0 0;
            margin-right: 5px;
            transition: background-color 0.3s ease;
        }
        
        .tab.active {
            background-color: var(--accent-color);
            color: white;
        }
        
        .tab-content {
            display: none;
            padding: 20px;
            border: 1px solid var(--light-color);
            border-top: none;
            border-radius: 0 0 5px 5px;
        }
        
        .tab-content.active {
            display: block;
        }
        
        .card-container {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .card {
            background-color: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }
        
        .card:hover {
            transform: translateY(-5px);
        }
        
        .card-header {
            background-color: var(--primary-color);
            color: white;
            padding: 15px;
            font-weight: bold;
        }
        
        .card-body {
            padding: 15px;
        }
        
        footer {
            background-color: var(--dark-color);
            color: white;
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
        }
        
        footer p {
            margin-bottom: 10px;
        }
        
        footer a {
            color: var(--accent-color);
            text-decoration: none;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        .notification {
            position: fixed;
            top: 20px;
            right: 20px;
            background-color: var(--accent-color);
            color: white;
            padding: 15px 25px;
            border-radius: 5px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
            transform: translateX(150%);
            transition: transform 0.3s ease;
            z-index: 1000;
        }
        
        .notification.show {
            transform: translateX(0);
        }
        
        @media (max-width: 768px) {
            header h1 {
                font-size: 2rem;
            }
            
            .card-container {
                grid-template-columns: 1fr;
            }
            
            .side-menu {
                width: 250px;
                left: -250px;
            }
        }
    </style>
</head>
<body>
    <button class="menu-toggle" id="menuToggle">
        <i class="fas fa-bars"></i>
    </button>
    
    <div class="overlay" id="overlay"></div>
    
    <div class="side-menu" id="sideMenu">
        <ul>
            <li><a href="#introduccion">Introducción</a></li>
            <li><a href="#origen">Origen e Historia</a></li>
            <li><a href="#base-matematica">Base Matemática</a></li>
            <li><a href="#algoritmo">Algoritmo Fundamental</a></li>
            <li><a href="#tipos">Tipos de Monte Carlo</a></li>
            <li><a href="#monte-carlo-cinetico">Monte Carlo Cinético</a></li>
            <li><a href="#monte-carlo-cuantico">Monte Carlo Cuántico</a></li>
            <li><a href="#aplicaciones">Aplicaciones</a></li>
            <li><a href="#ejemplos">Ejemplos</a></li>
            <li><a href="#ventajas-desventajas">Ventajas y Desventajas</a></li>
            <li><a href="#conclusion">Conclusión</a></li>
            <li><a href="#referencias">Referencias</a></li>
            <li><a href="#demostraciones">Demostraciones</a></li>
        </ul>
    </div>
    
    <header>
        <div class="container">
            <h1>El Método de Monte Carlo</h1>
            <p>Informe Académico: Matemáticas Computacionales, Simulación Estadística</p>
            <div class="author-info">
                <p>Profesor Ángel Chacín Ávila, Licenciado en Física, Especialista en Ciencias Computacionales</p>
                <p>Docente e Investigador de la Universidad Nacional Experimental de la Seguridad Núcleo Zulia</p>
                <p>Fecha: Septiembre 2025</p>
            </div>
        </div>
    </header>
    
    <div class="container">
        <div id="introduccion" class="section">
            <h2>1. Introducción</h2>
            <p>El Método de Monte Carlo (MC) es una clase de algoritmos computacionales que se basan en el muestreo aleatorio masivo para obtener resultados numéricos. Su esencia radica en utilizar la aleatoriedad para resolver problemas que, en principio, podrían ser deterministas. Es particularmente útil para modelar sistemas con un gran número de grados de libertad (como fluidos o partículas), problemas con compleja geometría o integrales multidimensionales que son intratables analíticamente.</p>
            <p>A diferencia de los métodos numéricos deterministas que proporcionan una única respuesta (aproximada pero determinista), Monte Carlo ofrece una solución estadística: una estimación acompañada de un intervalo de confianza que cuantifica la incertidumbre de la aproximación.</p>
            <div class="highlight">
                <p><strong>Punto clave:</strong> El método Monte Carlo transforma problemas deterministas complejos en problemas de estimación estadística manejables mediante el uso de la aleatoriedad.</p>
            </div>
        </div>
        
        <div id="origen" class="section">
            <h2>2. Origen e Historia</h2>
            <p>El nombre "Monte Carlo" fue acuñado en la década de 1940 por científicos (entre ellos Nicholas Metropolis, John von Neumann, y Stanisław Ulam) que trabajaban en el Proyecto Manhattan en el Laboratorio Nacional Los Álamos. El nombre proviene del famoso casino de Mónaco, haciendo alusión a los juegos de azar y la aleatoriedad que son centrales en el método.</p>
            <p>Sin embargo, la idea subyacente es anterior. A finales del siglo XVIII, Buffon y Laplace propusieron un método geométrico ("la aguja de Buffon") para estimar el valor de π lanzando una aguja sobre un suelo rayado, un experimento que es el precursor conceptual de Monte Carlo.</p>
            <p>El desarrollo crucial llegó con la invención de la computadora electrónica. Stanisław Ulam, mientras se recuperaba de una enfermedad, jugaba al solitario y se preguntaba sobre la probabilidad de ganar. Dada la complejidad combinatoria del problema, concibió la idea de simular múltiples partidas y contar las victorias. Al comentar esta idea con John von Neumann, se dieron cuenta del potencial de usar computadoras para realizar experimentos de muestreo estadístico a gran escala, aplicándolo inicialmente a problemas de difusión de neutrones en el diseño de armas nucleares.</p>
            <div class="card-container">
                <div class="card">
                    <div class="card-header">Figura clave: Stanisław Ulam</div>
                    <div class="card-body">
                        <p>Matemático polaco-estadounidense que concibió la idea del método Monte Carlo mientras se recuperaba de una enfermedad.</p>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">Figura clave: John von Neumann</div>
                    <div class="card-body">
                        <p>Matemático húngaro-estadounidense que colaboró con Ulam para desarrollar las primeras implementaciones computacionales del método.</p>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">Figura clave: Nicholas Metropolis</div>
                    <div class="card-body">
                        <p>Físico estadounidense que contribuyó al desarrollo del método y co-desarrolló el algoritmo de Metropolis-Hastings.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="base-matematica" class="section">
            <h2>3. Base Matemática y Estadística</h2>
            <p>El corazón del Método de Monte Carlo late gracias a dos teoremas fundamentales de la teoría de la probabilidad.</p>
            
            <h3>3.1. Ley de los Grandes Números (LGN)</h3>
            <p>Este teorema establece que el promedio de una muestra grande de variables aleatorias independientes e idénticamente distribuidas (i.i.d.) converge al valor esperado teórico de esa variable.</p>
            
            <div class="formula">
                Formalmente, si \(X_1, X_2, ..., X_n\) son variables i.i.d. con \(\mathbb{E}[X_i] = \mu\), entonces:<br>
                \(\overline{X_n} = \frac{1}{n} \sum_{i=1}^{n} X_i \overset{n \to \infty}{\longrightarrow} \mu \quad \text{(casi seguramente)}\)
            </div>
            
            <p>En el contexto de MC, si queremos estimar una integral \(I = \int_a^b f(x)  dx\), la reinterpretamos como una esperanza: \(I = (b-a) \cdot \mathbb{E}[f(X)]\), donde \(X \sim \mathcal{U}(a, b)\) (distribución uniforme). La LGN nos garantiza que si generamos \(n\) puntos \(x_i\) uniformemente en \([a, b]\) y calculamos el promedio de \(f(x_i)\), este convergerá al valor verdadero de la integral.</p>
            
            <h3>3.2. Teorema del Límite Central (TLC)</h3>
            <p>El TLC proporciona la precisión de la estimación de Monte Carlo. Establece que la distribución del promedio muestral \(\overline{X_n}\) se aproxima a una distribución normal a medida que \(n\) crece, independientemente de la distribución original de \(X\).</p>
            
            <div class="formula">
                Formalmente:<br>
                \(\sqrt{n} (\overline{X_n} - \mu) \overset{d}{\longrightarrow} \mathcal{N}(0, \sigma^2)\)<br>
                donde \(\sigma^2\) es la varianza de \(X\).
            </div>
            
            <p>Esto implica que el error de la estimación, \(|\overline{X_n} - \mu|\), es del orden de \(O(\sigma / \sqrt{n})\). La key insight aquí es que la tasa de convergencia es \(O(1/\sqrt{n})\), independiente de la dimensionalidad del problema. Esta es la ventaja crucial sobre los métodos deterministas (como las reglas de cuadratura), cuyo error a menudo se degrada exponencialmente con el número de dimensiones.</p>
            
            <div class="highlight">
                <p><strong>Insight fundamental:</strong> La tasa de convergencia del método Monte Carlo es independiente de la dimensionalidad del problema, lo que lo hace especialmente útil para problemas de alta dimensión donde los métodos tradicionales fallan.</p>
            </div>
        </div>
        
        <div id="algoritmo" class="section">
            <h2>4. Algoritmo Fundamental y Estructura General</h2>
            <p>El esquema básico para estimar una integral/esperanza \(\mu = \mathbb{E}[f(X)]\) mediante Monte Carlo Crudo es:</p>
            
            <ol>
                <li><strong>Definir el dominio:</strong> Identificar el espacio de posibles entradas (variables).</li>
                <li><strong>Generar muestras aleatorias:</strong> Generar \(N\) muestras \(x_1, x_2, ..., x_N\) de la distribución de probabilidad de \(X\) (usando generadores de número pseudoaleatorios).</li>
                <li><strong>Calcular la función:</strong> Para cada muestra, calcular el valor de la función \(f(x_i)\).</li>
                <li><strong>Agregar los resultados:</strong> Promediar los resultados y, si es necesario, escalar.
                    <div class="formula">
                        \(\hat{\mu}_N = \frac{1}{N} \sum_{i=1}^{N} f(x_i)\)
                    </div>
                </li>
                <li><strong>Estimar el error:</strong> Calcular la varianza muestral y el intervalo de confianza.
                    <div class="formula">
                        \(\hat{\sigma}_N^2 = \frac{1}{N-1} \sum_{i=1}^{N} (f(x_i) - \hat{\mu}_N)^2\)
                    </div>
                    El error estándar es \(\hat{\sigma}_N / \sqrt{N}\). Un intervalo de confianza del 95% para \(\mu\) es aproximadamente \(\hat{\mu}_N \pm 1.96 \cdot \hat{\sigma}_N / \sqrt{N}\).
                </li>
            </ol>
            
            <div class="tabs">
                <div class="tab active" data-tab="python-code">Python</div>
                <div class="tab" data-tab="fortran-code">Fortran</div>
            </div>
            
            <div id="python-code" class="tab-content active">
                <div class="code-block">
                    <pre><code class="language-python"># Implementación básica del método Monte Carlo para estimar una integral
import numpy as np

def monte_carlo_integration(f, a, b, N):
    # Generar muestras aleatorias uniformes en [a, b]
    samples = np.random.uniform(a, b, N)
    
    # Evaluar la función en las muestras
    f_values = f(samples)
    
    # Estimación de la integral
    integral = (b - a) * np.mean(f_values)
    
    # Estimación del error
    variance = (b - a)**2 * np.var(f_values)
    error = np.sqrt(variance / N)
    
    # Intervalo de confianza del 95%
    confidence_interval = [integral - 1.96 * error, integral + 1.96 * error]
    
    return {
        'estimate': integral,
        'error': error,
        'confidence_interval': confidence_interval
    }

# Ejemplo: estimar la integral de f(x) = x^2 en [0, 1]
result = monte_carlo_integration(lambda x: x**2, 0, 1, 10000)
print(f"Estimación: {result['estimate']} ± {result['error']}")
print(f"Intervalo de confianza 95%: [{result['confidence_interval'][0]}, {result['confidence_interval'][1]}]")</code></pre>
                </div>
            </div>
            
            <div id="fortran-code" class="tab-content">
                <div class="code-block">
                    <pre><code class="language-fortran">program monte_carlo_integration
    implicit none
    integer, parameter :: N = 10000
    real(8), parameter :: a = 0.0d0, b = 1.0d0
    real(8) :: integral, error, variance, sum_f, sum_f2
    real(8) :: x, f, random
    integer :: i
    
    ! Inicializar generador de números aleatorios
    call random_seed()
    
    sum_f = 0.0d0
    sum_f2 = 0.0d0
    
    do i = 1, N
        ! Generar número aleatorio uniforme en [a, b]
        call random_number(random)
        x = a + random * (b - a)
        
        ! Evaluar la función f(x) = x^2
        f = x**2
        
        sum_f = sum_f + f
        sum_f2 = sum_f2 + f**2
    end do
    
    ! Estimación de la integral
    integral = (b - a) * sum_f / N
    
    ! Estimación de la varianza
    variance = (b - a)**2 * (sum_f2 / N - (sum_f / N)**2)
    
    ! Estimación del error
    error = sqrt(variance / N)
    
    ! Resultados
    print *, "Estimación: ", integral, " +/- ", error
    print *, "Intervalo de confianza 95%: [", integral - 1.96d0 * error, ", ", integral + 1.96d0 * error, "]"
    
end program monte_carlo_integration</code></pre>
                </div>
            </div>
        </div>
        
        <div id="tipos" class="section">
            <h2>5. Tipos y Clasificaciones del Método de Monte Carlo</h2>
            
            <h3>5.1. Monte Carlo Crudo (Plain MC)</h3>
            <p>Es la forma más simple, como se describió anteriormente. Su principal desventaja es la lenta convergencia \(O(1/\sqrt{n})\) y puede ser ineficiente si la función \(f\) tiene una alta varianza.</p>
            
            <h3>5.2. Muestreo por Importancia (Importance Sampling)</h3>
            <p>Esta técnica busca reducir la varianza de la estimación muestreando preferentemente de regiones donde la función \(f(x)\) es grande o más "importante". Se introduce una nueva distribución de propuesta \(g(x)\) y se reescribe la integral:</p>
            
            <div class="formula">
                \(\int f(x)  dx = \int \frac{f(x)}{g(x)} g(x)  dx = \mathbb{E}_g\left[ \frac{f(X)}{g(X)} \right]\)
            </div>
            
            <p>Las muestras se toman de \(g(x)\) en lugar de la distribución original. Una elección inteligente de \(g(x)\) puede dramáticamente reducir la varianza.</p>
            
            <h3>5.3. Cadenas de Markov Monte Carlo (MCMC)</h3>
            <p>Es un conjunto de métodos para muestrear de distribuciones de probabilidad complejas y multidimensionales, especialmente cuando la función de densidad es conocida solo hasta una constante de normalización (común en inferencia bayesiana). En lugar de generar muestras independientes, MCMC genera una secuencia de muestras (una "cadena") donde cada muestra depende de la anterior. El algoritmo más popular es el Metropolis-Hastings.</p>
            
            <div class="highlight">
                <h4>Algoritmo Metropolis-Hastings:</h4>
                <p>Comienza con un punto inicial \(x_0\). Para cada iteración:</p>
                <ol>
                    <li>Propón un nuevo punto \(x'\) desde una distribución de propuesta \(Q(x'|x_t)\).</li>
                    <li>Calcula la razón de aceptación \(\alpha = \min \left(1, \frac{P(x') Q(x_t|x')}{P(x_t) Q(x'|x_t)} \right)\).</li>
                    <li>Genera un número aleatorio \(u \sim \mathcal{U}(0,1)\).</li>
                    <li>Si \(u \leq \alpha\), acepta el nuevo punto: \(x_{t+1} = x'\). De lo contrario, recházalo: \(x_{t+1} = x_t\).</li>
                </ol>
            </div>
            
            <h3>5.4. Cuasi-Monte Carlo</h3>
            <p>Este método reemplaza las secuencias pseudoaleatorias por secuencias de baja discrepancia (como las secuencias de Sobol' o Halton). Estas secuencias están diseñadas para cubrir el espacio de muestreo de manera más uniforme que los números aleatorios. La tasa de convergencia puede acercarse a \(O(1/n)\), que es mejor que el MC clásico. Sin embargo, la estimación del error es más complicada al no depender de la probabilidad clásica.</p>
            
            <div class="tabs">
                <div class="tab active" data-tab="comparison">Comparación de métodos</div>
                <div class="tab" data-tab="implementation">Implementación MCMC</div>
            </div>
            
            <div id="comparison" class="tab-content active">
                <div class="table-container">
                    <table>
                        <thead>
                            <tr>
                                <th>Método</th>
                                <th>Tasa de convergencia</th>
                                <th>Ventajas</th>
                                <th>Desventajas</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Monte Carlo Crudo</td>
                                <td>\(O(1/\sqrt{n})\)</td>
                                <td>Simple de implementar, robusto</td>
                                <td>Convergencia lenta, ineficiente para funciones de alta varianza</td>
                            </tr>
                            <tr>
                                <td>Muestreo por Importancia</td>
                                <td>Variable (depende de g(x))</td>
                                <td>Reduce varianza, más eficiente</td>
                                <td>Requiere conocimiento previo para elegir g(x)</td>
                            </tr>
                            <tr>
                                <td>MCMC</td>
                                <td>\(O(1/\sqrt{n})\) (pero con constante menor)</td>
                                <td>Funciona con distribuciones complejas</td>
                                <td>Muestras correlacionadas, convergencia lenta</td>
                            </tr>
                            <tr>
                                <td>Cuasi-Monte Carlo</td>
                                <td>Cerca de \(O(1/n)\)</td>
                                <td>Convergencia más rápida</td>
                                <td>Estimación de error complicada</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            
            <div id="implementation" class="tab-content">
                <div class="tabs">
                    <div class="tab active" data-tab="mcmc-python">Python</div>
                    <div class="tab" data-tab="mcmc-fortran">Fortran</div>
                </div>
                
                <div id="mcmc-python" class="tab-content active">
                    <div class="code-block">
                        <pre><code class="language-python"># Implementación del algoritmo Metropolis-Hastings
import numpy as np

def metropolis_hastings(target_log_density, proposal_sampler, proposal_log_density, 
                        initial_state, n_samples):
    current_sample = initial_state
    samples = [current_sample]
    accepted = 0
    
    for _ in range(n_samples):
        # Proponer un nuevo estado
        proposed_sample = proposal_sampler(current_sample)
        
        # Calcular la razón de aceptación
        log_alpha = (target_log_density(proposed_sample) + 
                    proposal_log_density(current_sample, proposed_sample) - 
                    target_log_density(current_sample) - 
                    proposal_log_density(proposed_sample, current_sample))
        
        alpha = min(1.0, np.exp(log_alpha))
        
        # Aceptar o rechazar
        if np.random.random() < alpha:
            current_sample = proposed_sample
            accepted += 1
        
        samples.append(current_sample)
    
    return {
        'samples': np.array(samples),
        'acceptance_rate': accepted / n_samples
    }

# Ejemplo: muestrear de una distribución normal estándar
def normal_log_density(x):
    return -0.5 * x**2 - 0.5 * np.log(2 * np.pi)

def normal_proposal_sampler(x):
    return x + (np.random.random() - 0.5) * 2  # Propuesta uniforme en [x-1, x+1]

def normal_proposal_log_density(x, y):
    # Densidad uniforme en [x-1, x+1]
    if y >= x - 1 and y <= x + 1:
        return -np.log(2)
    return -np.inf

result = metropolis_hastings(
    normal_log_density,
    normal_proposal_sampler,
    normal_proposal_log_density,
    0.0,  # Estado inicial
    10000  # Número de muestras
)

print(f"Tasa de aceptación: {result['acceptance_rate']}")</code></pre>
                    </div>
                </div>
                
                <div id="mcmc-fortran" class="tab-content">
                    <div class="code-block">
                        <pre><code class="language-fortran">program metropolis_hastings
    implicit none
    integer, parameter :: n_samples = 10000
    real(8), parameter :: initial_state = 0.0d0
    real(8) :: current_sample, proposed_sample, log_alpha, alpha, u
    real(8) :: current_log_density, proposed_log_density
    real(8) :: forward_log_density, backward_log_density
    integer :: i, accepted
    real(8), dimension(n_samples+1) :: samples
    
    ! Inicializar generador de números aleatorios
    call random_seed()
    
    current_sample = initial_state
    samples(1) = current_sample
    accepted = 0
    
    do i = 1, n_samples
        ! Proponer un nuevo estado
        call random_number(u)
        proposed_sample = current_sample + (u - 0.5d0) * 2.0d0
        
        ! Calcular log-densidades
        current_log_density = normal_log_density(current_sample)
        proposed_log_density = normal_log_density(proposed_sample)
        forward_log_density = normal_proposal_log_density(current_sample, proposed_sample)
        backward_log_density = normal_proposal_log_density(proposed_sample, current_sample)
        
        ! Calcular la razón de aceptación
        log_alpha = proposed_log_density + backward_log_density - &
                    current_log_density - forward_log_density
        
        if (log_alpha > 0.0d0) then
            alpha = 1.0d0
        else
            alpha = exp(log_alpha)
        end if
        
        ! Aceptar o rechazar
        call random_number(u)
        if (u <= alpha) then
            current_sample = proposed_sample
            accepted = accepted + 1
        end if
        
        samples(i+1) = current_sample
    end do
    
    print *, "Tasa de aceptación: ", dble(accepted) / dble(n_samples)
    
contains
    function normal_log_density(x) result(log_density)
        real(8), intent(in) :: x
        real(8) :: log_density
        log_density = -0.5d0 * x**2 - 0.5d0 * log(2.0d0 * acos(-1.0d0))
    end function normal_log_density
    
    function normal_proposal_log_density(x, y) result(log_density)
        real(8), intent(in) :: x, y
        real(8) :: log_density
        if (y >= x - 1.0d0 .and. y <= x + 1.0d0) then
            log_density = -log(2.0d0)
        else
            log_density = -huge(log_density)  - Infinito
        end if
    end function normal_proposal_log_density
    
end program metropolis_hastings</code></pre>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="monte-carlo-cinetico" class="section">
            <h2>6. Monte Carlo Cinético (KMC)</h2>
            <p>El Monte Carlo Cinético (Kinetic Monte Carlo, KMC) es una variante del método Monte Carlo diseñada para simular la evolución temporal de sistemas que involucran procesos estocásticos con tasas de transición conocidas. A diferencia del Monte Carlo tradicional, que se enfoca en estados de equilibrio, el KMC modela la cinética de los procesos y cómo el sistema evoluciona con el tiempo.</p>
            
            <h3>6.1. Fundamentos del KMC</h3>
            <p>El KMC se basa en el algoritmo de Bortz, Kalos y Lebowitz (BKL), también conocido como algoritmo de "nacimiento y muerte". El método simula procesos estocásticos seleccionando aleatoriamente qué proceso ocurre a continuación, basándose en sus tasas de transición relativas.</p>
            
            <div class="formula">
                La probabilidad de que un proceso \(i\) ocurra en el siguiente paso está dada por:<br>
                \(P_i = \frac{r_i}{\sum_j r_j}\)
            </div>
            
            <p>donde \(r_i\) es la tasa de transición del proceso \(i\) y el denominador es la suma de todas las tasas de transición posibles.</p>
            
            <h3>6.2. Algoritmo KMC</h3>
            <p>El algoritmo básico del KMC funciona de la siguiente manera:</p>
            
            <ol>
                <li>Identificar todos los procesos posibles en el estado actual del sistema y sus tasas de transición \(r_i\).</li>
                <li>Calcular la tasa total \(R = \sum_i r_i\).</li>
                <li>Generar un número aleatorio \(u_1 \in [0, 1]\) y seleccionar el proceso \(k\) tal que \(\sum_{i=1}^{k-1} r_i < u_1 \cdot R \leq \sum_{i=1}^{k} r_i\).</li>
                <li>Generar otro número aleatorio \(u_2 \in [0, 1]\) y avanzar el tiempo en \(\Delta t = -\ln(u_2) / R\).</li>
                <li>Ejecutar el proceso seleccionado y actualizar el estado del sistema.</li>
                <li>Repetir desde el paso 1.</li>
            </ol>
            
            <h3>6.3. Aplicaciones del KMC</h3>
            <p>El Monte Carlo Cinético es ampliamente utilizado en:</p>
            <ul>
                <li><strong>Crecimiento de películas delgadas:</strong> Simulación de deposición atómica, epitaxia y crecimiento de cristales.</li>
                <li><strong>Difusión en sólidos:</strong> Modelado de la migración de átomos e impurezas en materiales.</li>
                <li><strong>Reacciones químicas superficiales:</strong> Simulación de catálisis y reacciones en superficies.</li>
                <li><strong>Evolución de microestructuras:</strong> Estudio de la formación de granos y defectos en materiales.</li>
            </ul>
            
            <div class="highlight">
                <p><strong>Ventaja clave del KMC:</strong> Permite simular escalas de tiempo mucho más largas que los métodos de dinámica molecular tradicional, ya que no requiere resolver las ecuaciones de movimiento para cada átomo en cada paso de tiempo.</p>
            </div>
        </div>
        
        <div id="monte-carlo-cuantico" class="section">
            <h2>7. Monte Carlo Cuántico (QMC)</h2>
            <p>El Monte Carlo Cuántico (Quantum Monte Carlo, QMC) es una clase de métodos que utilizan técnicas de Monte Carlo para resolver problemas de mecánica cuántica. Estos métodos son particularmente útiles para sistemas de muchos cuerpos donde las soluciones analíticas son imposibles y otros métodos numéricos son computacionalmente prohibitivos.</p>
            
            <h3>7.1. Fundamentos del QMC</h3>
            <p>El QMC se basa en la representación de la función de onda cuántica o la matriz de densidad en términos de variables estocásticas. Los métodos más comunes incluyen:</p>
            <ul>
                <li><strong>Monte Carlo de Difusión (DMC):</strong> Resuelve la ecuación de Schrödinger en tiempo imaginario.</li>
                <li><strong>Monte Carlo de Trayectorias (Path Integral):</strong> Utiliza la formulación de integrales de camino de Feynman.</li>
                <li><strong>Monte Carlo de Función de Green:</strong> Calcula la función de Green del sistema.</li>
                <li><strong>Monte Carlo Variacional (VMC):</strong> Optimiza los parámetros de una función de onda de prueba.</li>
            </ul>
            
            <h3>7.2. Algoritmo de Monte Carlo de Difusión</h3>
            <p>El algoritmo básico del DMC funciona de la siguiente manera:</p>
            
            <ol>
                <li>Representar la función de onda como un conjunto de "caminantes" (walkers) en el espacio de configuración.</li>
                <li>Para cada paso de tiempo en tiempo imaginario:
                    <ul>
                        <li>Mover cada caminante aleatoriamente según el operador de difusión.</li>
                        <li>Aplicar un potencial de ramificación (branching) basado en la energía potencial.</li>
                        <li>Eliminar o duplicar caminantes según su peso.</li>
                    </ul>
                </li>
                <li>Calcular propiedades del sistema a partir de la distribución de caminantes.</li>
            </ol>
            
            <h3>7.3. Aplicaciones del QMC</h3>
            <p>El Monte Carlo Cuántico se utiliza en:</p>
            <ul>
                <li><strong>Física de la materia condensada:</strong> Estudio de superconductores, aislantes topológicos y sistemas fuertemente correlacionados.</li>
                <li><strong>Química cuántica:</strong> Cálculo de estructuras electrónicas y energías de moléculas.</li>
                <li><strong>Física nuclear:</strong> Simulación de la estructura de núcleos atómicos.</li>
                <li><strong>Materiales cuánticos:</strong> Diseño de nuevos materiales con propiedades cuánticas específicas.</li>
            </ul>
            
            <div class="highlight">
                <p><strong>Desafío del QMC:</strong> El problema del "signo fermiónico" limita la aplicabilidad del método a sistemas fermiónicos, ya que la función de onda antisimétrica cambia de signo, lo que lleva a cancelaciones destructivas y ruido estadístico.</p>
            </div>
        </div>
        
        <div id="aplicaciones" class="section">
            <h2>8. Aplicaciones en Diversos Campos</h2>
            
            <h3>8.1. Física e Ingeniería</h3>
            <ul>
                <li><strong>Simulación de partículas:</strong> Modelado del transporte de fotones, neutrones y electrones en medios (usado en dosimetría radiológica y diseño de reactores nucleares).</li>
                <li><strong>Mecánica estadística:</strong> Simulación de sistemas de muchas partículas, como el modelo de Ising para ferromagnetismo, usando MCMC.</li>
                <li><strong>Ingeniería de materiales:</strong> Estudio de fracturas, fatiga y propagación de grietas.</li>
                <li><strong>Crecimiento de películas delgadas:</strong> Simulación de deposición atómica y formación de nanoestructuras usando KMC.</li>
            </ul>
            
            <h3>8.2. Finanzas y Economía</h3>
            <ul>
                <li><strong>Valoración de opciones financieras:</strong> Cálculo del precio de opciones con payoffs complejos (como opciones asiáticas o de barrera) simulando miles de trayectorias posibles del precio del activo subyacente (modelos como Black-Scholes-Merton).</li>
                <li><strong>Gestión de riesgos (VaR - Value at Risk):</strong> Evaluación del riesgo de carteras de inversión simulando escenarios económicos extremos.</li>
                <li><strong>Modelos econométricos:</strong> Simulación de modelos macroeconómicos complejos con múltiples variables estocásticas.</li>
            </ul>
            
            <h3>8.3. Inteligencia Artificial y Aprendizaje Automático</h3>
            <ul>
                <li><strong>Inferencia Bayesiana:</strong> MCMC es una herramienta fundamental para estimar los parámetros posteriores en modelos bayesianos complejos.</li>
                <li><strong>Algoritmos de optimización y búsqueda:</strong> Algoritmos como Simulated Annealing (Recocido Simulado) utilizan principios de Monte Carlo para escapar de óptimos locales.</li>
                <li><strong>Aprendizaje por Refuerzo:</strong> Los algoritmos Monte Carlo Tree Search (MCTS) son clave en el éxito de sistemas como AlphaGo. Los métodos de predicción también usan MC para evaluar políticas.</li>
            </ul>
            
            <h3>8.4. Biología Computacional y Medicina</h3>
            <ul>
                <li><strong>Genética de poblaciones:</strong> Simulación de la deriva genética y la evolución.</li>
                <li><strong>Dockeo molecular:</strong> Simulación del acoplamiento de fármacos a proteínas objetivo.</li>
                <li><strong>Epidemiología:</strong> Modelado de la propagación de enfermedades mediante modelos compartimentales estocásticos (modelos SIR).</li>
            </ul>
            
            <h3>8.5. Otros Campos</h3>
            <ul>
                <li><strong>Gráficos por computadora (Renderizado):</strong> Algoritmos de path tracing y ray tracing que simulan el transporte de la luz para generar imágenes fotorrealistas.</li>
                <li><strong>Matemáticas puras:</strong> Estimación de constantes, solución de ecuaciones integrales.</li>
            </ul>
            
            <div class="card-container">
                <div class="card">
                    <div class="card-header">Física de Partículas</div>
                    <div class="card-body">
                        <p>Simulación de colisiones de partículas en aceleradores como el LHC del CERN.</p>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">Finanzas Cuantitativas</div>
                    <div class="card-body">
                        <p>Valoración de productos derivados complejos y gestión de riesgos financieros.</p>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">Inteligencia Artificial</div>
                    <div class="card-body">
                        <p>Algoritmos de búsqueda como Monte Carlo Tree Search usados en AlphaGo.</p>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">Epidemiología</div>
                    <div class="card-body">
                        <p>Modelado de la propagación de enfermedades como COVID-19 para evaluar intervenciones.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="ejemplos" class="section">
            <h2>9. Ejemplos de Implementación</h2>
            
            <h3>9.1. Simulación Monte Carlo de deposición de películas delgadas de Fe</h3>
            <p>Este ejemplo muestra una simulación de Monte Carlo Cinético para el crecimiento de películas delgadas de hierro (Fe) mediante deposición física de vapor (PVD). El modelo incluye procesos de deposición, difusión superficial y desorción.</p>
            
            <div class="tabs">
                <div class="tab active" data-tab="fe-python">Python</div>
                <div class="tab" data-tab="fe-fortran">Fortran</div>
            </div>
            
            <div id="fe-python" class="tab-content active">
                <div class="code-block">
                    <pre><code class="language-python"># Simulación Monte Carlo de deposición de películas delgadas de Fe
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

class KMCThinFilm:
    def __init__(self, size=(100, 100), temperature=500, deposition_rate=0.1):
        """
        Inicializa la simulación KMC para crecimiento de películas delgadas.
        
        Parámetros:
        - size: Tupla (nx, ny) con el tamaño de la superficie.
        - temperature: Temperatura del sustrato en Kelvin.
        - deposition_rate: Tasa de deposición en ML/s (monocapas por segundo).
        """
        self.nx, self.ny = size
        self.temperature = temperature
        self.deposition_rate = deposition_rate
        
        # Constantes
        self.kb = 8.617e-5  # Constante de Boltzmann en eV/K
        self.E_diff = 0.3    # Energía de difusión en eV
        self.E_des = 0.8     # Energía de desorción en eV
        self.nu = 1e13       # Frecuencia de intento en Hz
        
        # Inicializar la superficie (0 = vacío, 1 = átomo de Fe)
        self.surface = np.zeros((self.nx, self.ny))
        
        # Lista de eventos posibles (depósito, difusión, desorción)
        self.events = []
        
        # Tiempo de simulación
        self.time = 0.0
        
        # Contador de átomos depositados
        self.deposited_atoms = 0
        
    def get_neighbors(self, i, j):
        """Obtiene los vecinos de un sitio (i, j) en la superficie."""
        neighbors = []
        for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
            ni, nj = (i + di) % self.nx, (j + dj) % self.ny
            neighbors.append((ni, nj))
        return neighbors
    
    def calculate_diffusion_rate(self, i, j):
        """Calcula la tasa de difusión desde el sitio (i, j)."""
        if self.surface[i, j] == 0:
            return 0.0  # No hay átomo para difundir
        
        # Contar vecinos (coordinación)
        neighbors = self.get_neighbors(i, j)
        coordination = sum(self.surface[ni, nj] for ni, nj in neighbors)
        
        # La tasa de difusión depende de la coordinación
        # Menos coordinación = mayor tasa de difusión
        energy_barrier = self.E_diff * (1 - 0.1 * coordination)
        rate = self.nu * np.exp(-energy_barrier / (self.kb * self.temperature))
        
        return rate
    
    def calculate_desorption_rate(self, i, j):
        """Calcula la tasa de desorción desde el sitio (i, j)."""
        if self.surface[i, j] == 0:
            return 0.0  # No hay átomo para desorber
        
        # Contar vecinos (coordinación)
        neighbors = self.get_neighbors(i, j)
        coordination = sum(self.surface[ni, nj] for ni, nj in neighbors)
        
        # La tasa de desorción depende de la coordinación
        # Más coordinación = menor tasa de desorción
        energy_barrier = self.E_des * (1 - 0.2 * coordination)
        rate = self.nu * np.exp(-energy_barrier / (self.kb * self.temperature))
        
        return rate
    
    def update_events(self):
        """Actualiza la lista de eventos posibles."""
        self.events = []
        
        # Evento de deposición (puede ocurrir en cualquier sitio vacío)
        empty_sites = np.argwhere(self.surface == 0)
        if len(empty_sites) > 0:
            # Tasa total de deposición
            total_deposition_rate = self.deposition_rate * len(empty_sites)
            self.events.append(('deposition', None, None, total_deposition_rate))
        
        # Eventos de difusión y desorción
        for i in range(self.nx):
            for j in range(self.ny):
                if self.surface[i, j] == 1:  # Hay un átomo
                    # Difusión a cada vecino
                    neighbors = self.get_neighbors(i, j)
                    for ni, nj in neighbors:
                        if self.surface[ni, nj] == 0:  # El sitio vecino está vacío
                            rate = self.calculate_diffusion_rate(i, j) / len(neighbors)
                            self.events.append(('diffusion', (i, j), (ni, nj), rate))
                    
                    # Desorción
                    rate = self.calculate_desorption_rate(i, j)
                    self.events.append(('desorption', (i, j), None, rate))
    
    def execute_event(self, event_type, site1, site2):
        """Ejecuta un evento en la superficie."""
        if event_type == 'deposition':
            # Elegir un sitio vacío al azar
            empty_sites = np.argwhere(self.surface == 0)
            if len(empty_sites) > 0:
                idx = np.random.randint(len(empty_sites))
                i, j = empty_sites[idx]
                self.surface[i, j] = 1
                self.deposited_atoms += 1
                
        elif event_type == 'diffusion':
            i, j = site1
            ni, nj = site2
            # Mover el átomo
            self.surface[i, j] = 0
            self.surface[ni, nj] = 1
            
        elif event_type == 'desorption':
            i, j = site1
            # Eliminar el átomo
            self.surface[i, j] = 0
    
    def step(self):
        """Realiza un paso de la simulación KMC."""
        # Actualizar la lista de eventos
        self.update_events()
        
        if not self.events:
            return False  # No hay eventos posibles
        
        # Calcular la tasa total
        total_rate = sum(rate for _, _, _, rate in self.events)
        
        # Elegir un evento según sus tasas
        r = np.random.random() * total_rate
        cumulative = 0.0
        
        for event_type, site1, site2, rate in self.events:
            cumulative += rate
            if r <= cumulative:
                # Ejecutar el evento seleccionado
                self.execute_event(event_type, site1, site2)
                
                # Avanzar el tiempo
                dt = -np.log(np.random.random()) / total_rate
                self.time += dt
                
                return True
        
        return False
    
    def run(self, max_steps=1000):
        """Ejecuta la simulación durante un número máximo de pasos."""
        for _ in range(max_steps):
            if not self.step():
                break
    
    def visualize(self):
        """Visualiza la superficie actual."""
        plt.figure(figsize=(10, 8))
        plt.imshow(self.surface, cmap='hot', interpolation='nearest')
        plt.colorbar(label='Presencia de átomo (0=vacío, 1=Fe)')
        plt.title(f'Superficie de Fe a t={self.time:.2e}s, Átomos depositados: {self.deposited_atoms}')
        plt.xlabel('Posición x')
        plt.ylabel('Posición y')
        plt.show()

# Ejemplo de uso
if __name__ == "__main__":
    # Crear la simulación
    simulation = KMCThinFilm(size=(50, 50), temperature=500, deposition_rate=0.1)
    
    # Ejecutar la simulación
    simulation.run(max_steps=1000)
    
    # Visualizar el resultado
    simulation.visualize()
    
    print(f"Tiempo de simulación: {simulation.time:.2e} s")
    print(f"Átomos depositados: {simulation.deposited_atoms}")
    print(f"Monocapas depositadas: {simulation.deposited_atoms / (simulation.nx * simulation.ny):.2f}")</code></pre>
                </div>
            </div>
            
            <div id="fe-fortran" class="tab-content">
                <div class="code-block">
                    <pre><code class="language-fortran">PROGRAM simulacion_montecarlo_pulverizacion_3d_fe
IMPLICIT NONE
INTEGER, PARAMETER :: TAM_REJILLA = 300, ALTURA_MAX = 150
REAL, PARAMETER :: KB = 8.617E-5, TEMP_SUBSTRATO = 500.0, TEMP_PLASMA = 1000.0,
ADHESION_BASE = 0.98
INTEGER, DIMENSION(TAM_REJILLA,TAM_REJILLA,ALTURA_MAX) :: material
INTEGER, DIMENSION(TAM_REJILLA,TAM_REJILLA) :: altura_max_local
INTEGER :: i, j, k, num_eventos, semilla(8), depositos, difusiones, num_corridas, corrida
REAL :: tiempo, prob_difusion_const, energia_difusion, tasa_eventos, adhesion, energia_promedio
CHARACTER(LEN=50) :: nombre_archivo

! Solicitar número de corridas al usuario
PRINT *, 'Ingrese el número de corridas deseadas:'
READ *, num_corridas
IF (num_corridas <= 0) THEN
PRINT *, 'Error: El número de corridas debe ser positivo'
STOP
END IF

! Bucle para múltiples corridas
DO corrida = 1, num_corridas
! Generar parámetros aleatorios
CALL RANDOM_SEED()
CALL RANDOM_NUMBER(energia_difusion)
energia_difusion = 0.01 + 0.24 * energia_difusion ! Rango: 0.01 a 0.25
CALL RANDOM_NUMBER(tasa_eventos)
tasa_eventos = 10000.0 + 90000.0 * tasa_eventos ! Rango: 10,000 a 100,000
CALL RANDOM_NUMBER(energia_promedio)
energia_promedio = 2.0 + 3.0 * energia_promedio ! Rango: 2.0 a 5.0
CALL RANDOM_NUMBER(adhesion)
adhesion = ADHESION_BASE + 0.03 * adhesion ! Rango: 0.98 a 1.01 (cortado a 1.0)

! Precalcular constante de difusión
prob_difusion_const = EXP(-energia_difusion / (KB * TEMP_SUBSTRATO))

! Inicializar semilla para números aleatorios (diferente por corrida)
CALL SYSTEM_CLOCK(i)
semilla = i + 37 * (/ (j - 1, j = 1, 8) /) + corrida
CALL RANDOM_SEED(PUT=semilla)

! Inicializar rejilla
CALL inicializar_rejilla(material, altura_max_local, TAM_REJILLA, ALTURA_MAX)

! Simulación con distribución de Poisson
num_eventos = 0
depositos = 0
difusiones = 0
tiempo = 0.0
DO WHILE (num_eventos < 300000) ! MAX_PARTICULAS fijo en 300,000
CALL simular_evento(material, altura_max_local, num_eventos, 300000, &
tasa_eventos, tiempo, energia_difusion, TEMP_SUBSTRATO, &
KB, adhesion, TEMP_PLASMA, TAM_REJILLA, ALTURA_MAX, &
depositos, difusiones, prob_difusion_const, energia_promedio)
IF (num_eventos >= 300000) EXIT
END DO
PRINT *, 'Corrida', corrida, ': Depósitos =', depositos, 'Difuiones =', difusiones, 'Tiempo =', tiempo

! Generar nombre de archivo único
WRITE(nombre_archivo, '(A,I0.3,A,F4.2,A,F6.0,A,F4.1,A)') &
'fe_3d_altura_c', corrida, '_ed', energia_difusion, '_te', tasa_eventos, '_ep', energia_promedio,
'.dat'

! Guardar resultados
CALL guardar_datos(material, TAM_REJILLA, ALTURA_MAX, nombre_archivo, &
energia_difusion, TEMP_SUBSTRATO, tasa_eventos, adhesion)
END DO

PRINT *, 'Simulaciones para Fe completadas'
STOP

CONTAINS

SUBROUTINE inicializar_rejilla(material, altura_max_local, tam_rejilla, altura_max)
INTEGER, DIMENSION(tam_rejilla,tam_rejilla,altura_max), INTENT(OUT) :: material
INTEGER, DIMENSION(tam_rejilla,tam_rejilla), INTENT(OUT) :: altura_max_local
INTEGER, INTENT(IN) :: tam_rejilla, altura_max
INTEGER :: i, j
material = 0
DO i = 1, tam_rejilla
DO j = 1, tam_rejilla
material(i,j,1) = 26  ! 26 es el número atómico del Hierro (Fe)
material(i,j,2) = 26
END DO
END DO
altura_max_local = 2
END SUBROUTINE inicializar_rejilla

INTEGER FUNCTION find_z_max(columna)
INTEGER, INTENT(IN) :: columna(ALTURA_MAX)
INTEGER :: k
DO k = ALTURA_MAX, 1, -1
IF (columna(k) > 0) THEN
find_z_max = k
RETURN
END IF
END DO
find_z_max = 0
END FUNCTION find_z_max

SUBROUTINE safe_random(r)
REAL, INTENT(OUT) :: r
CALL RANDOM_NUMBER(r)
r = 1E-10 + (1 - 2E-10) * r
END SUBROUTINE safe_random

SUBROUTINE simular_evento(material, altura_max_local, num_eventos, max_part, &
tasa_eventos, tiempo, energia_difusion, temp_substrato, &
kb, adhesion, temp_plasma, tam_rejilla, altura_max, &
depositos, difusiones, prob_difusion_const, energia_promedio)
INTEGER, DIMENSION(tam_rejilla,tam_rejilla,altura_max), INTENT(INOUT) :: material
INTEGER, DIMENSION(tam_rejilla,tam_rejilla), INTENT(INOUT) :: altura_max_local
INTEGER, INTENT(INOUT) :: num_eventos, depositos, difusiones
INTEGER, INTENT(IN) :: max_part, tam_rejilla, altura_max
REAL, INTENT(IN) :: tasa_eventos, energia_difusion, temp_substrato, kb, &
adhesion, temp_plasma, prob_difusion_const, energia_promedio
REAL, INTENT(INOUT) :: tiempo
INTEGER :: x, y, z_max, nuevo_x, nuevo_y
REAL :: energia, prob_adhesion, r, r_tiempo
REAL, PARAMETER :: MIN_R = 1E-10, MAX_ENERGIA = 5.0

num_eventos = num_eventos + 1
IF (num_eventos > max_part) num_eventos = max_part

CALL RANDOM_NUMBER(r_tiempo)
r_tiempo = MAX(MIN_R, r_tiempo)
tiempo = tiempo + (-LOG(r_tiempo) / tasa_eventos)

IF (num_eventos <= max_part) THEN
CALL safe_random(r)
x = 1 + FLOOR(r * (tam_rejilla-1))
CALL safe_random(r)
y = 1 + FLOOR(r * (tam_rejilla-1))
z_max = MAXVAL(altura_max_local(MAX(1,x-1):MIN(tam_rejilla,x+1), &
MAX(1,y-1):MIN(tam_rejilla,y+1)))
CALL safe_random(r)
energia = energia_promedio + (r - 0.5) * MAX_ENERGIA
CALL safe_random(r)
prob_adhesion = adhesion * (1.0 + (energia / MAX_ENERGIA) * 0.2)
IF (prob_adhesion > r .AND. z_max < altura_max) THEN
depositos = depositos + 1
material(x,y,z_max+1) = 26  ! 26 es el número atómico del Hierro (Fe)
altura_max_local(x,y) = z_max + 1
IF (z_max > 2) THEN
CALL safe_random(r)
IF (prob_difusion_const > r) THEN
difusiones = difusiones + 1
nuevo_x = MODULO((x + MERGE(-1,1,r<0.5) - 1), tam_rejilla) + 1
nuevo_y = MODULO((y + MERGE(-1,1,r>0.5) - 1), tam_rejilla) + 1
material(nuevo_x, nuevo_y, z_max) = 26
material(x, y, z_max) = 0
altura_max_local(x,y) = find_z_max(material(x,y,:))
altura_max_local(nuevo_x,nuevo_y) = find_z_max(material(nuevo_x,nuevo_y,:))
END IF
END IF
END IF
END IF
END SUBROUTINE simular_evento

SUBROUTINE guardar_datos(material, tam_rejilla, altura_max, nombre_archivo, &
energia_difusion, temp_substrato, tasa_eventos, adhesion)
INTEGER, DIMENSION(tam_rejilla,tam_rejilla,altura_max), INTENT(IN) :: material
INTEGER, INTENT(IN) :: tam_rejilla, altura_max
CHARACTER(LEN=*), INTENT(IN) :: nombre_archivo
REAL, INTENT(IN) :: energia_difusion, temp_substrato, tasa_eventos, adhesion
INTEGER :: i, j, z_max
OPEN(UNIT=10, FILE=nombre_archivo, STATUS='REPLACE')
WRITE(10, '(A)') '# Simulación KMC 3D para pulverización (Fe)'
WRITE(10, '(A, I0)') '# Tamaño de la rejilla (TAM_REJILLA): ', tam_rejilla
WRITE(10, '(A, I0)') '# Altura máxima (ALTURA_MAX): ', altura_max
WRITE(10, '(A, I0)') '# Número de eventos (MAX_PARTICULAS): ', 300000
WRITE(10, '(A, F8.3)') '# Energía de difusión (eV): ', energia_difusion
WRITE(10, '(A, F8.1)') '# Temperatura del sustrato (K): ', temp_substrato
WRITE(10, '(A, F8.1)') '# Tasa de eventos: ', tasa_eventos
WRITE(10, '(A, F8.3)') '# Probabilidad de adhesión (ADHESION): ', adhesion
WRITE(10, '(A, F8.1)') '# Energía promedio (eV): ', energia_promedio
WRITE(10, '(A)') '# Formato: i j altura(i,j)'
DO i = 1, tam_rejilla
DO j = 1, tam_rejilla
z_max = find_z_max(material(i,j,:))
WRITE(10, '(I4, I4, I4)') i, j, z_max
END DO
END DO
CLOSE(10)
END SUBROUTINE guardar_datos
END PROGRAM simulacion_montecarlo_pulverizacion_3d_fe</code></pre>
                </div>
            </div>
        </div>
        
        <div id="ventajas-desventajas" class="section">
            <h2>10. Ventajas y Desventajas</h2>
            
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Ventajas</th>
                            <th>Desventajas</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Simpleza conceptual: Fácil de implementar para problemas básicos.</td>
                            <td>Convergencia lenta: La tasa \(O(1/\sqrt{n})\) requiere muchas muestras para una alta precisión.</td>
                        </tr>
                        <tr>
                            <td>Independencia dimensional: El error es independiente del número de dimensiones del problema.</td>
                            <td>Generación de números aleatorios: La calidad de los resultados depende de la calidad del generador de números aleatorios.</td>
                        </tr>
                        <tr>
                            <td>Robustez: Funciona bien con funciones discontinuas o de alta frecuencia.</td>
                            <td>Puede ser computacionalmente costoso: Millones de evaluaciones de una función compleja pueden ser lentas.</td>
                        </tr>
                        <tr>
                            <td>Proporciona una medida del error: El intervalo de confianza es una salida natural del método.</td>
                            <td>Ineficiencia en sampling naïve: Puede muestrear regiones "poco importantes", requiriendo técnicas avanzadas (e.g., Importance Sampling).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="highlight">
                <p><strong>Conclusión clave:</strong> A pesar de sus limitaciones, el método Monte Carlo es insustituible para problemas de alta dimensionalidad donde los métodos deterministas tradicionales fallan. Su capacidad para proporcionar estimaciones con medidas de error lo hace particularmente valioso en aplicaciones científicas y de ingeniería.</p>
            </div>
        </div>
        
        <div id="conclusion" class="section">
            <h2>11. Conclusión</h2>
            <p>El Método de Monte Carlo es una herramienta computacional poderosa y extraordinariamente versátil que transforma problemas deterministas complejos en problemas de estimación estadística manejables. Su fundamento en la Ley de los Grandes Números y el Teorema del Límite Central le proporciona un sólido marco teórico. Aunque su convergencia puede ser lenta, su independencia de la dimensionalidad lo hace insustituible para problemas en espacios de alta dimensión donde los métodos tradicionales fallan.</p>
            <p>Desde su origen en la física nuclear hasta su aplicación actual en finanzas, inteligencia artificial y más, Monte Carlo ha demostrado ser un pilar de la computación científica moderna. El desarrollo continuo de técnicas de reducción de varianza (como MCMC y Quasi-MC) asegura que su relevancia y aplicabilidad seguirán expandiéndose en el futuro.</p>
            <p>Las variantes especializadas como el Monte Carlo Cinético (KMC) y el Monte Carlo Cuántico (QMC) han extendido aún más el alcance del método, permitiendo simular procesos dinámicos y sistemas cuánticos que antes eran inaccesibles. Estas técnicas continúan evolucionando y encontrando nuevas aplicaciones en campos emergentes como la nanotecnología, la computación cuántica y la bioingeniería.</p>
        </div>
        
        <div id="referencias" class="section">
            <h2>12. Referencias Bibliográficas</h2>
            <ol>
                <li>Metropolis, N., & Ulam, S. (1949). The Monte Carlo Method. <em>Journal of the American Statistical Association</em>.</li>
                <li>Rubinstein, R. Y., & Kroese, D. P. (2016). <em>Simulation and the Monte Carlo Method</em> (3rd ed.). Wiley.</li>
                <li>Robert, C. P., & Casella, G. (2004). <em>Monte Carlo Statistical Methods</em> (2nd ed.). Springer.</li>
                <li>Hammersley, J. M., & Handscomb, D. C. (1964). <em>Monte Carlo Methods</em>. Methuen & Co Ltd.</li>
                <li>Liu, J. S. (2008). <em>Monte Carlo Strategies in Scientific Computing</em>. Springer.</li>
                <li>Kalos, M. H., & Whitlock, P. A. (2008). <em>Monte Carlo Methods</em> (2nd ed.). Wiley-VCH.</li>
                <li>Fichthorn, K. A., & Weinberg, W. H. (1991). Theoretical foundations of dynamical Monte Carlo simulations. <em>Journal of Chemical Physics</em>, 95(2), 1090-1096.</li>
                <li>Foulkes, W. M. C., Mitas, L., Needs, R. J., & Rajagopal, G. (2001). Quantum Monte Carlo simulations of solids. <em>Reviews of Modern Physics</em>, 73(1), 33.</li>
            </ol>
        </div>
        
        <div id="demostraciones" class="section">
            <h2>13. Demostraciones Interactivas</h2>
            
            <h3>Estimación de π usando el Método de Monte Carlo</h3>
            <p>Una de las demostraciones más clásicas del método Monte Carlo es la estimación del valor de π. Si generamos puntos aleatorios en un cuadrado de lado 2 (de -1 a 1 en ambos ejes), la proporción de puntos que caen dentro del círculo unitario (radio 1) se aproxima a π/4.</p>
            
            <div class="interactive-demo">
                <div class="demo-controls">
                    <button id="startPiSimulation">Iniciar simulación</button>
                    <button id="pausePiSimulation">Pausar</button>
                    <button id="resetPiSimulation">Reiniciar</button>
                    <span>Muestras: <span id="piSamples">0</span></span>
                    <span>Estimación de π: <span id="piEstimate">0</span></span>
                </div>
                <div class="canvas-container">
                    <canvas id="piCanvas" width="400" height="400"></canvas>
                </div>
            </div>
            
            <h3>Convergencia del Método de Monte Carlo</h3>
            <p>Esta demostración muestra cómo la estimación de una integral converge al valor verdadero a medida que aumenta el número de muestras, de acuerdo con la Ley de los Grandes Números.</p>
            
            <div class="interactive-demo">
                <div class="demo-controls">
                    <button id="startConvergenceSimulation">Iniciar simulación</button>
                    <button id="pauseConvergenceSimulation">Pausar</button>
                    <button id="resetConvergenceSimulation">Reiniciar</button>
                </div>
                <div class="canvas-container">
                    <canvas id="convergenceCanvas" width="800" height="400"></canvas>
                </div>
            </div>
        </div>
    </div>
    
    <footer>
        <div class="container">
            <p>&copy; 2025 Ángel Chacín Ávila</p>
            <p>Se publica con licencia <a href="https://www.gnu.org/licenses/gpl-3.0.en.html" target="_blank">GPL</a></p>
        </div>
    </footer>
    
    <div class="notification" id="notification">
        ¡Operación completada con éxito!
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-javascript.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-fortran.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Menú desplegable
            const menuToggle = document.getElementById('menuToggle');
            const sideMenu = document.getElementById('sideMenu');
            const overlay = document.getElementById('overlay');
            
            menuToggle.addEventListener('click', function() {
                sideMenu.classList.toggle('active');
                overlay.classList.toggle('active');
            });
            
            overlay.addEventListener('click', function() {
                sideMenu.classList.remove('active');
                overlay.classList.remove('active');
            });
            
            // Navegación suave
            const navLinks = document.querySelectorAll('.side-menu a');
            navLinks.forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href');
                    const targetSection = document.querySelector(targetId);
                    
                    // Cerrar el menú
                    sideMenu.classList.remove('active');
                    overlay.classList.remove('active');
                    
                    // Scroll suave
                    window.scrollTo({
                        top: targetSection.offsetTop - 20,
                        behavior: 'smooth'
                    });
                });
            });
            
            // Sistema de pestañas
            const tabs = document.querySelectorAll('.tab');
            tabs.forEach(tab => {
                tab.addEventListener('click', function() {
                    const tabContainer = this.parentElement;
                    const tabContents = tabContainer.nextElementSibling;
                    
                    // Desactivar todas las pestañas y contenidos
                    tabContainer.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                    if (tabContents) {
                        tabContents.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
                    }
                    
                    // Activar la pestaña actual y su contenido
                    this.classList.add('active');
                    const tabId = this.getAttribute('data-tab');
                    if (tabContents) {
                        const content = tabContents.querySelector(`#${tabId}`);
                        if (content) {
                            content.classList.add('active');
                        }
                    }
                });
            });
            
            // Notificaciones
            const notification = document.getElementById('notification');
            
            function showNotification(message) {
                notification.textContent = message;
                notification.classList.add('show');
                
                setTimeout(() => {
                    notification.classList.remove('show');
                }, 3000);
            }
            
            // Simulación de estimación de π
            const piCanvas = document.getElementById('piCanvas');
            const piCtx = piCanvas.getContext('2d');
            const piSamplesElement = document.getElementById('piSamples');
            const piEstimateElement = document.getElementById('piEstimate');
            
            let piAnimationId = null;
            let piSamples = 0;
            let piInside = 0;
            let piPaused = false;
            
            function drawPiSimulation() {
                if (piPaused) return;
                
                // Generar múltiples puntos por frame para acelerar la simulación
                for (let i = 0; i < 100; i++) {
                    const x = Math.random() * 2 - 1;  // [-1, 1]
                    const y = Math.random() * 2 - 1;  // [-1, 1]
                    
                    piSamples++;
                    
                    // Comprobar si el punto está dentro del círculo unitario
                    if (x * x + y * y <= 1) {
                        piInside++;
                        // Dibujar punto dentro del círculo en verde
                        piCtx.fillStyle = '#00C853';
                    } else {
                        // Dibujar punto fuera del círculo en naranja
                        piCtx.fillStyle = '#FF6F00';
                    }
                    
                    // Dibujar el punto
                    piCtx.beginPath();
                    piCtx.arc(
                        (x + 1) * piCanvas.width / 2,  // Convertir de [-1,1] a [0, width]
                        (y + 1) * piCanvas.height / 2, // Convertir de [-1,1] a [0, height]
                        1,  // Radio del punto
                        0,
                        Math.PI * 2
                    );
                    piCtx.fill();
                }
                
                // Actualizar estimación de π
                const piEstimate = 4 * piInside / piSamples;
                piSamplesElement.textContent = piSamples.toLocaleString();
                piEstimateElement.textContent = piEstimate.toFixed(6);
                
                piAnimationId = requestAnimationFrame(drawPiSimulation);
            }
            
            // Dibujar el círculo unitario y el cuadrado
            function drawPiSetup() {
                piCtx.clearRect(0, 0, piCanvas.width, piCanvas.height);
                
                // Dibujar el cuadrado
                piCtx.strokeStyle = '#6A1B9A';
                piCtx.lineWidth = 2;
                piCtx.strokeRect(0, 0, piCanvas.width, piCanvas.height);
                
                // Dibujar el círculo unitario
                piCtx.beginPath();
                piCtx.arc(
                    piCanvas.width / 2,
                    piCanvas.height / 2,
                    piCanvas.width / 2,
                    0,
                    Math.PI * 2
                );
                piCtx.stroke();
            }
            
            document.getElementById('startPiSimulation').addEventListener('click', function() {
                if (!piAnimationId) {
                    piPaused = false;
                    drawPiSimulation();
                    showNotification('Simulación de π iniciada');
                }
            });
            
            document.getElementById('pausePiSimulation').addEventListener('click', function() {
                piPaused = !piPaused;
                if (!piPaused && piAnimationId) {
                    drawPiSimulation();
                    showNotification('Simulación reanudada');
                } else {
                    showNotification('Simulación pausada');
                }
            });
            
            document.getElementById('resetPiSimulation').addEventListener('click', function() {
                if (piAnimationId) {
                    cancelAnimationFrame(piAnimationId);
                    piAnimationId = null;
                }
                piSamples = 0;
                piInside = 0;
                piPaused = false;
                piSamplesElement.textContent = '0';
                piEstimateElement.textContent = '0';
                drawPiSetup();
                showNotification('Simulación reiniciada');
            });
            
            // Inicializar el canvas de π
            drawPiSetup();
            
            // Simulación de convergencia
            const convergenceCanvas = document.getElementById('convergenceCanvas');
            const convergenceCtx = convergenceCanvas.getContext('2d');
            
            let convergenceAnimationId = null;
            let convergenceSamples = 0;
            let convergencePaused = false;
            let convergenceEstimates = [];
            
            // Función a integrar: f(x) = x^2 en [0,1]
            function f(x) {
                return x * x;
            }
            
            // Valor verdadero de la integral
            const trueValue = 1/3;
            
            function drawConvergenceSimulation() {
                if (convergencePaused) return;
                
                // Generar múltiples muestras por frame
                for (let i = 0; i < 100; i++) {
                    convergenceSamples++;
                    
                    // Generar muestra aleatoria uniforme en [0, 1]
                    const x = Math.random();
                    
                    // Calcular la estimación actual de la integral
                    const currentEstimate = (convergenceEstimates.length > 0 ? 
                        convergenceEstimates[convergenceEstimates.length - 1].estimate * (convergenceSamples - 1) + f(x) : 
                        f(x)) / convergenceSamples;
                    
                    // Guardar la estimación
                    convergenceEstimates.push({
                        samples: convergenceSamples,
                        estimate: currentEstimate
                    });
                }
                
                // Limpiar el canvas
                convergenceCtx.clearRect(0, 0, convergenceCanvas.width, convergenceCanvas.height);
                
                // Dibujar el valor verdadero
                convergenceCtx.strokeStyle = '#00C853';
                convergenceCtx.lineWidth = 2;
                convergenceCtx.beginPath();
                convergenceCtx.moveTo(0, convergenceCanvas.height - trueValue * convergenceCanvas.height);
                convergenceCtx.lineTo(convergenceCanvas.width, convergenceCanvas.height - trueValue * convergenceCanvas.height);
                convergenceCtx.stroke();
                
                // Dibujar la estimación
                convergenceCtx.strokeStyle = '#FF6F00';
                convergenceCtx.lineWidth = 2;
                convergenceCtx.beginPath();
                
                const maxSamples = Math.max(10000, convergenceSamples);
                
                convergenceEstimates.forEach((point, index) => {
                    const x = (point.samples / maxSamples) * convergenceCanvas.width;
                    const y = convergenceCanvas.height - point.estimate * convergenceCanvas.height;
                    
                    if (index === 0) {
                        convergenceCtx.moveTo(x, y);
                    } else {
                        convergenceCtx.lineTo(x, y);
                    }
                });
                
                convergenceCtx.stroke();
                
                // Dibujar etiquetas
                convergenceCtx.fillStyle = '#6A1B9A';
                convergenceCtx.font = '14px Arial';
                convergenceCtx.fillText(`Valor verdadero: ${trueValue.toFixed(6)}`, 10, 20);
                convergenceCtx.fillText(`Estimación actual: ${convergenceEstimates.length > 0 ? convergenceEstimates[convergenceEstimates.length - 1].estimate.toFixed(6) : '0'}`, 10, 40);
                convergenceCtx.fillText(`Muestras: ${convergenceSamples.toLocaleString()}`, 10, 60);
                
                convergenceAnimationId = requestAnimationFrame(drawConvergenceSimulation);
            }
            
            document.getElementById('startConvergenceSimulation').addEventListener('click', function() {
                if (!convergenceAnimationId) {
                    convergencePaused = false;
                    drawConvergenceSimulation();
                    showNotification('Simulación de convergencia iniciada');
                }
            });
            
            document.getElementById('pauseConvergenceSimulation').addEventListener('click', function() {
                convergencePaused = !convergencePaused;
                if (!convergencePaused && convergenceAnimationId) {
                    drawConvergenceSimulation();
                    showNotification('Simulación reanudada');
                } else {
                    showNotification('Simulación pausada');
                }
            });
            
            document.getElementById('resetConvergenceSimulation').addEventListener('click', function() {
                if (convergenceAnimationId) {
                    cancelAnimationFrame(convergenceAnimationId);
                    convergenceAnimationId = null;
                }
                convergenceSamples = 0;
                convergencePaused = false;
                convergenceEstimates = [];
                convergenceCtx.clearRect(0, 0, convergenceCanvas.width, convergenceCanvas.height);
                showNotification('Simulación reiniciada');
            });
            
            // Animación de las tarjetas al hacer scroll
            const cards = document.querySelectorAll('.card');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver((entries, observer) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.style.opacity = 1;
                        entry.target.style.transform = 'translateY(0)';
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            cards.forEach(card => {
                card.style.opacity = 0;
                card.style.transform = 'translateY(20px)';
                card.style.transition = 'opacity 0.5s ease, transform 0.5s ease';
                observer.observe(card);
            });
        });
    </script>
</body>
</html>
